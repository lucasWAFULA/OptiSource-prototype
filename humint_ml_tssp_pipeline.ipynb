{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "27278cfe",
      "metadata": {},
      "source": [
        "# Hybrid Modelling of HUMINT Source Performance: ML-TSSP Model\n",
        "\n",
        "This notebook walks through the **entire HUMINT ML-TSSP pipeline** as implemented in the project: data generation/preprocessing, classification (XGBoost + SMOTE), regression (GRU for reliability/deception), TSSP optimization, cost analysis, and advanced metrics (EVPI, EMV, sensitivity, efficiency frontier).\n",
        "\n",
        "Run from **project root** so `src` and config resolve correctly. GLPK (or CBC) must be installed for TSSP and advanced metrics."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3d1dae58",
      "metadata": {},
      "source": [
        "## 1. Title and Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c977678f",
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "# Add project root to path (run notebook from project root). Matches src/pipeline.py logic.\n",
        "PROJECT_ROOT = Path.cwd()\n",
        "if str(PROJECT_ROOT) not in sys.path:\n",
        "    sys.path.insert(0, str(PROJECT_ROOT))\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "\n",
        "from src.data import (\n",
        "    generate_humint_dataset,\n",
        "    prepare_classification_data,\n",
        "    prepare_regression_data,\n",
        "    scale_features,\n",
        "    load_features_from_file,\n",
        ")\n",
        "from src.ml import ClassificationModelTrainer, RegressionModelTrainer\n",
        "from src.optimization import TSSPModel\n",
        "from src.analysis import (\n",
        "    analyze_costs,\n",
        "    generate_cost_report,\n",
        ")\n",
        "from src.analysis.advanced_metrics import (\n",
        "    calculate_evpi,\n",
        "    calculate_emv,\n",
        "    sensitivity_analysis,\n",
        "    generate_advanced_metrics_report,\n",
        "    calculate_efficiency_frontier,\n",
        "    plot_efficiency_frontier,\n",
        ")\n",
        "from src.utils.config import (\n",
        "    PROJECT_ROOT as CONFIG_ROOT,\n",
        "    MODELS_DIR,\n",
        "    OUTPUT_DIR,\n",
        "    BEHAVIOR_CLASSES,\n",
        "    RECOURSE_COSTS,\n",
        "    CLASSIFICATION_FEATURES_FILE,\n",
        "    REGRESSION_FEATURES_FILE,\n",
        ")\n",
        "# Use config paths; config PROJECT_ROOT is parent of src/\n",
        "PROJECT_ROOT = CONFIG_ROOT\n",
        "if str(PROJECT_ROOT) not in sys.path:\n",
        "    sys.path.insert(0, str(PROJECT_ROOT))\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "RANDOM_SEED = 42\n",
        "np.random.seed(RANDOM_SEED)\n",
        "print(f\"Project root: {PROJECT_ROOT}\")\n",
        "print(f\"Models dir: {MODELS_DIR}\")\n",
        "print(f\"Output dir: {OUTPUT_DIR}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5157377d",
      "metadata": {},
      "source": [
        "## 2. Data — Load or Generate Synthetic HUMINT Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4fb214ef",
      "metadata": {},
      "outputs": [],
      "source": [
        "DATA_PATH = PROJECT_ROOT / \"humint_source_dataset_15000_enhanced.csv\"\n",
        "if DATA_PATH.exists():\n",
        "    print(f\"Loading dataset from: {DATA_PATH}\")\n",
        "    df = pd.read_csv(DATA_PATH)\n",
        "else:\n",
        "    print(f\"Generating new dataset with 15000 sources...\")\n",
        "    df = generate_humint_dataset(\n",
        "        n_sources=15000,\n",
        "        random_seed=RANDOM_SEED,\n",
        "        output_path=DATA_PATH,\n",
        "    )\n",
        "print(f\"Dataset loaded: {len(df)} sources\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08dae565",
      "metadata": {},
      "outputs": [],
      "source": [
        "# EDA\n",
        "print(\"Shape:\", df.shape)\n",
        "print(\"\\nColumns:\", list(df.columns))\n",
        "print(\"\\nBehavior class counts:\")\n",
        "print(df[\"behavior_class\"].value_counts())\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81e944dd",
      "metadata": {},
      "outputs": [],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d9edf219",
      "metadata": {},
      "source": [
        "## 3. Classification — Behavior Prediction (XGBoost + SMOTE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "257c208b",
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, y_train, X_test, y_test, label_encoder = prepare_classification_data(\n",
        "    df,\n",
        "    feature_file=CLASSIFICATION_FEATURES_FILE,\n",
        "    random_state=RANDOM_SEED,\n",
        ")\n",
        "classification_trainer = ClassificationModelTrainer(random_state=RANDOM_SEED)\n",
        "X_train, y_train = classification_trainer.apply_smote(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aea59680",
      "metadata": {},
      "outputs": [],
      "source": [
        "xgb_results = classification_trainer.train_xgboost(X_train, y_train, X_test, y_test)\n",
        "m = xgb_results[\"metrics\"]\n",
        "print(f\"Accuracy:  {m['accuracy']:.4f}\")\n",
        "print(f\"F1:        {m['f1']:.4f}\")\n",
        "print(f\"Precision: {m['precision']:.4f}\")\n",
        "print(f\"Recall:    {m['recall']:.4f}\")\n",
        "if \"roc_auc\" in m:\n",
        "    print(f\"ROC-AUC:   {m['roc_auc']:.4f}\")\n",
        "classification_trainer.best_model = xgb_results[\"model\"]\n",
        "classification_trainer.best_model_name = \"xgboost\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "920e6bc1",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "\n",
        "y_pred = classification_trainer.best_model.predict(X_test)\n",
        "fig, ax = plt.subplots(figsize=(8, 6))\n",
        "ConfusionMatrixDisplay.from_predictions(y_test, y_pred, ax=ax)\n",
        "plt.title(\"Confusion Matrix (XGBoost)\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "259d9ce4",
      "metadata": {},
      "outputs": [],
      "source": [
        "classification_trainer.save_model(MODELS_DIR / \"classification_model.pkl\", label_encoder)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2d3a98d4",
      "metadata": {},
      "source": [
        "## 4. Regression — Reliability and Deception Scores (GRU)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a268140",
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train_r, y_train_r, X_test_r, y_test_r = prepare_regression_data(\n",
        "    df,\n",
        "    feature_file=REGRESSION_FEATURES_FILE,\n",
        "    target_col=\"reliability_score\",\n",
        "    random_state=RANDOM_SEED,\n",
        ")\n",
        "X_train_scaled, X_test_scaled, reliability_scaler = scale_features(X_train_r, X_test_r)\n",
        "reliability_trainer = RegressionModelTrainer(random_state=RANDOM_SEED)\n",
        "rel_results = reliability_trainer.train_gru(\n",
        "    X_train_scaled, y_train_r, X_test_scaled, y_test_r\n",
        ")\n",
        "reliability_trainer.best_model = rel_results[\"model\"]\n",
        "reliability_trainer.best_model_name = \"gru\"\n",
        "rm = rel_results[\"metrics\"]\n",
        "print(f\"Reliability GRU R²:   {rm['r2']:.4f}\")\n",
        "print(f\"Reliability GRU RMSE: {rm['rmse']:.4f}\")\n",
        "print(f\"Reliability GRU MAE:  {rm['mae']:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "228e1b46",
      "metadata": {},
      "outputs": [],
      "source": [
        "reliability_trainer.save_model(MODELS_DIR / \"reliability_model.keras\")\n",
        "joblib.dump(reliability_scaler, MODELS_DIR / \"reliability_scaler.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "02de6edc",
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train_d, y_train_d, X_test_d, y_test_d = prepare_regression_data(\n",
        "    df,\n",
        "    feature_file=REGRESSION_FEATURES_FILE,\n",
        "    target_col=\"deception_score\",\n",
        "    random_state=RANDOM_SEED,\n",
        ")\n",
        "X_train_ds, X_test_ds, deception_scaler = scale_features(X_train_d, X_test_d)\n",
        "deception_trainer = RegressionModelTrainer(random_state=RANDOM_SEED)\n",
        "dec_results = deception_trainer.train_gru(\n",
        "    X_train_ds, y_train_d, X_test_ds, y_test_d\n",
        ")\n",
        "deception_trainer.best_model = dec_results[\"model\"]\n",
        "deception_trainer.best_model_name = \"gru\"\n",
        "dm = dec_results[\"metrics\"]\n",
        "print(f\"Deception GRU R²:   {dm['r2']:.4f}\")\n",
        "print(f\"Deception GRU RMSE: {dm['rmse']:.4f}\")\n",
        "print(f\"Deception GRU MAE:  {dm['mae']:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da68775c",
      "metadata": {},
      "outputs": [],
      "source": [
        "deception_trainer.save_model(MODELS_DIR / \"deception_model.keras\")\n",
        "joblib.dump(deception_scaler, MODELS_DIR / \"deception_scaler.pkl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "36861f17",
      "metadata": {},
      "source": [
        "## 5. TSSP — Two-Stage Stochastic Optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04dcfaaf",
      "metadata": {},
      "outputs": [],
      "source": [
        "opt_n_sources = 100\n",
        "opt_n_tasks = 10\n",
        "sources_df = df.head(opt_n_sources).copy()\n",
        "sources = sources_df[\"source_id\"].tolist()\n",
        "tasks = [f\"TASK_{i:03d}\" for i in range(1, opt_n_tasks + 1)]\n",
        "\n",
        "features = load_features_from_file(CLASSIFICATION_FEATURES_FILE)\n",
        "available_features = [f for f in features if f in sources_df.columns]\n",
        "X_pred = sources_df[available_features]\n",
        "proba = classification_trainer.best_model.predict_proba(X_pred)\n",
        "\n",
        "behavior_probabilities = {}\n",
        "for idx, source_id in enumerate(sources):\n",
        "    for class_idx, behavior in enumerate(BEHAVIOR_CLASSES):\n",
        "        behavior_probabilities[(source_id, behavior)] = float(proba[idx, class_idx])\n",
        "\n",
        "reg_features = load_features_from_file(REGRESSION_FEATURES_FILE)\n",
        "available_reg = [f for f in reg_features if f in sources_df.columns]\n",
        "X_reg = sources_df[available_reg]\n",
        "X_reg_rel = reliability_scaler.transform(X_reg)\n",
        "X_reg_rel = X_reg_rel.reshape(X_reg_rel.shape[0], 1, X_reg_rel.shape[1])\n",
        "reliability_predictions = reliability_trainer.best_model.predict(X_reg_rel, verbose=0).flatten()\n",
        "X_reg_dec = deception_scaler.transform(X_reg)\n",
        "X_reg_dec = X_reg_dec.reshape(X_reg_dec.shape[0], 1, X_reg_dec.shape[1])\n",
        "deception_predictions = deception_trainer.best_model.predict(X_reg_dec, verbose=0).flatten()\n",
        "sources_df[\"predicted_reliability\"] = reliability_predictions\n",
        "sources_df[\"predicted_deception\"] = deception_predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c795d56",
      "metadata": {},
      "outputs": [],
      "source": [
        "stage1_costs = {}\n",
        "for idx, source_id in enumerate(sources):\n",
        "    row = sources_df[sources_df[\"source_id\"] == source_id].iloc[0]\n",
        "    base = 10.0 * (1.0 - row[\"predicted_reliability\"])\n",
        "    for task_id in tasks:\n",
        "        stage1_costs[(source_id, task_id)] = round(base, 2)\n",
        "\n",
        "information_values = {}\n",
        "for idx, source_id in enumerate(sources):\n",
        "    row = sources_df[sources_df[\"source_id\"] == source_id].iloc[0]\n",
        "    info_val = row.get(\"information_value\", 0.5)\n",
        "    base_value = (row[\"predicted_reliability\"] + info_val) / 2\n",
        "    for task_id in tasks:\n",
        "        information_values[(source_id, task_id)] = base_value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a970fcf4",
      "metadata": {},
      "outputs": [],
      "source": [
        "tssp_inputs = {\n",
        "    \"sources\": sources,\n",
        "    \"tasks\": tasks,\n",
        "    \"behavior_classes\": BEHAVIOR_CLASSES,\n",
        "    \"behavior_probabilities\": behavior_probabilities,\n",
        "    \"stage1_costs\": stage1_costs,\n",
        "    \"recourse_costs\": RECOURSE_COSTS,\n",
        "    \"information_values\": information_values,\n",
        "}\n",
        "tssp_model = TSSPModel(**tssp_inputs)\n",
        "tssp_model.build_model()\n",
        "success = tssp_model.solve(solver_name=\"glpk\")\n",
        "print(f\"TSSP solve success: {success}\")\n",
        "if success:\n",
        "    print(f\"Objective value: {tssp_model.solution.get('objective_value', None)}\")\n",
        "    n_assign = sum(1 for v in tssp_model.solution.get(\"assignments\", {}).values() if v)\n",
        "    print(f\"Number of assignments: {n_assign}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d42c2df",
      "metadata": {},
      "source": [
        "## 6. Cost Analysis and Reporting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "19757de1",
      "metadata": {},
      "outputs": [],
      "source": [
        "analysis_results = analyze_costs(tssp_model, output_dir=OUTPUT_DIR)\n",
        "decomposition = analysis_results[\"decomposition\"]\n",
        "verification = analysis_results[\"verification\"]\n",
        "print(\"Stage 1 cost:\", decomposition[\"stage1_cost\"])\n",
        "print(\"Stage 2 expected cost:\", decomposition[\"stage2_expected_cost\"])\n",
        "print(\"Verified:\", verification[\"verified\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ba53499",
      "metadata": {},
      "outputs": [],
      "source": [
        "report_path = OUTPUT_DIR / \"cost_analysis_report.txt\"\n",
        "report_text = generate_cost_report(decomposition, verification, output_path=report_path)\n",
        "print(report_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ba5d064",
      "metadata": {},
      "outputs": [],
      "source": [
        "pd.DataFrame({\n",
        "    \"Stage 1\": [decomposition[\"stage1_cost\"]],\n",
        "    \"Stage 2 (expected)\": [decomposition[\"stage2_expected_cost\"]],\n",
        "    \"Total\": [decomposition[\"stage1_cost\"] + decomposition[\"stage2_expected_cost\"]],\n",
        "})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "719e4fb7",
      "metadata": {},
      "source": [
        "## 7. Advanced Metrics — EVPI, EMV, Sensitivity, Efficiency Frontier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf6ab8f1",
      "metadata": {},
      "outputs": [],
      "source": [
        "evpi_results = None\n",
        "emv_results = None\n",
        "sensitivity_results = None\n",
        "frontier_results = None\n",
        "\n",
        "try:\n",
        "    evpi_results = calculate_evpi(\n",
        "        tssp_model=tssp_model,\n",
        "        behavior_classes=BEHAVIOR_CLASSES,\n",
        "        behavior_probabilities=tssp_inputs[\"behavior_probabilities\"],\n",
        "        sources=tssp_inputs[\"sources\"],\n",
        "        tasks=tssp_inputs[\"tasks\"],\n",
        "        stage1_costs=tssp_inputs[\"stage1_costs\"],\n",
        "        recourse_costs=tssp_inputs[\"recourse_costs\"],\n",
        "        solver_name=\"glpk\",\n",
        "    )\n",
        "    print(f\"EVPI: {evpi_results.get('evpi', 0):.2f}\")\n",
        "    print(f\"EVPI %: {evpi_results.get('evpi_percentage', 0):.2f}%\")\n",
        "except Exception as e:\n",
        "    print(f\"EVPI failed: {e}\")\n",
        "\n",
        "try:\n",
        "    emv_results = calculate_emv(\n",
        "        tssp_model=tssp_model,\n",
        "        information_values=tssp_inputs.get(\"information_values\"),\n",
        "    )\n",
        "    print(f\"EMV: {emv_results.get('emv', 0):.2f}\")\n",
        "    print(f\"Information value: {emv_results.get('information_value', 0):.2f}\")\n",
        "except Exception as e:\n",
        "    print(f\"EMV failed: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7dc6c5b2",
      "metadata": {},
      "outputs": [],
      "source": [
        "try:\n",
        "    sensitivity_results = sensitivity_analysis(\n",
        "        tssp_model=tssp_model,\n",
        "        behavior_classes=BEHAVIOR_CLASSES,\n",
        "        behavior_probabilities=tssp_inputs[\"behavior_probabilities\"],\n",
        "        sources=tssp_inputs[\"sources\"],\n",
        "        tasks=tssp_inputs[\"tasks\"],\n",
        "        stage1_costs=tssp_inputs[\"stage1_costs\"],\n",
        "        recourse_costs=tssp_inputs[\"recourse_costs\"],\n",
        "        variation_range=0.2,\n",
        "        solver_name=\"glpk\",\n",
        "        output_dir=OUTPUT_DIR,\n",
        "    )\n",
        "    print(\"Sensitivity analysis done. Baseline:\", sensitivity_results.get(\"baseline_value\"))\n",
        "except Exception as e:\n",
        "    print(f\"Sensitivity failed: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2fa906ae",
      "metadata": {},
      "outputs": [],
      "source": [
        "try:\n",
        "    frontier_results = calculate_efficiency_frontier(\n",
        "        sources=tssp_inputs[\"sources\"],\n",
        "        tasks=tssp_inputs[\"tasks\"],\n",
        "        behavior_classes=BEHAVIOR_CLASSES,\n",
        "        behavior_probabilities=tssp_inputs[\"behavior_probabilities\"],\n",
        "        stage1_costs=tssp_inputs[\"stage1_costs\"],\n",
        "        recourse_costs=tssp_inputs[\"recourse_costs\"],\n",
        "        n_scenarios=20,\n",
        "        solver_name=\"glpk\",\n",
        "    )\n",
        "    plot_efficiency_frontier(\n",
        "        frontier_results,\n",
        "        output_path=OUTPUT_DIR / \"efficiency_frontier.png\",\n",
        "    )\n",
        "    print(f\"Efficiency frontier: {len(frontier_results['frontier_points'])} points\")\n",
        "except Exception as e:\n",
        "    print(f\"Efficiency frontier failed: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b971cf57",
      "metadata": {},
      "outputs": [],
      "source": [
        "if evpi_results and emv_results and sensitivity_results:\n",
        "    try:\n",
        "        adv_report = generate_advanced_metrics_report(\n",
        "            evpi_results=evpi_results,\n",
        "            emv_results=emv_results,\n",
        "            sensitivity_results=sensitivity_results,\n",
        "            output_path=OUTPUT_DIR / \"advanced_metrics_report.txt\",\n",
        "        )\n",
        "        print(adv_report)\n",
        "    except Exception as e:\n",
        "        print(f\"Advanced metrics report failed: {e}\")\n",
        "else:\n",
        "    print(\"Skipping advanced metrics report (EVPI/EMV/sensitivity missing).\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ca1b309f",
      "metadata": {},
      "source": [
        "## 9. Allocation Efficiency — TSSP vs Deterministic vs Uniform\n",
        "\n",
        "Compare **TSSP** (Stage 1 + Stage 2, ML-driven) to **Stage-1-only** baselines:\n",
        "\n",
        "- **TSSP (optimal)**: Full two-stage model. Stage 1 assignment + Stage 2 (ML-based performance forecasting, recourse). Uses ML predictions throughout.\n",
        "- **Deterministic (greedy)**: **Stage 1 only.** Fixed rule: assign (source, task) pairs in ascending Stage 1 cost; each task ≥ 1 source, each source ≤ 1 task. No ML, no Stage 2.\n",
        "- **Uniform (round-robin)**: **Stage 1 only.** Fixed rule: each task → one source in round-robin order. No ML, no Stage 2.\n",
        "\n",
        "Deterministic and uniform serve as **baseline comparators**: they operate exclusively at Stage 1 (task assignment by fixed rules or equal allocation) and do not use ML or Stage 2. Allocation efficiency is compared on **Stage 1 cost** (apples-to-apples)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7777e34e",
      "metadata": {},
      "outputs": [],
      "source": [
        "from IPython.display import display, Image\n",
        "from src.analysis import evaluate_allocation_efficiency\n",
        "\n",
        "alloc_result = evaluate_allocation_efficiency(\n",
        "    tssp_model=tssp_model,\n",
        "    tssp_inputs=tssp_inputs,\n",
        "    output_dir=OUTPUT_DIR,\n",
        ")\n",
        "\n",
        "# Comparison table\n",
        "comparison_df = pd.DataFrame(alloc_result[\"comparison\"])[\n",
        "    [\"method\", \"stage1_cost\", \"stage2_cost\", \"total_cost\", \"n_assignments\", \"success\"]\n",
        "]\n",
        "display(comparison_df)\n",
        "\n",
        "# Relative to TSSP Stage 1 (allocation efficiency)\n",
        "print(\"\\nRelative to TSSP Stage 1 (allocation efficiency):\")\n",
        "if np.isfinite(alloc_result.get(\"deterministic_vs_tssp_stage1_pct\")):\n",
        "    print(f\"  Deterministic (greedy): {alloc_result['deterministic_vs_tssp_stage1_pct']:+.1f}%\")\n",
        "if np.isfinite(alloc_result.get(\"uniform_vs_tssp_stage1_pct\")):\n",
        "    print(f\"  Uniform (round-robin):  {alloc_result['uniform_vs_tssp_stage1_pct']:+.1f}%\")\n",
        "if alloc_result.get(\"plot_path\") and Path(alloc_result[\"plot_path\"]).exists():\n",
        "    display(Image(filename=str(alloc_result[\"plot_path\"])))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8cba5df2",
      "metadata": {},
      "source": [
        "## 8. (Optional) Run Full Pipeline in One Go"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c8ce27e",
      "metadata": {},
      "outputs": [],
      "source": [
        "from src.pipeline import MLTSSPPipeline\n",
        "\n",
        "data_path = PROJECT_ROOT / \"humint_source_dataset_15000_enhanced.csv\"\n",
        "pipeline = MLTSSPPipeline(data_path=data_path if data_path.exists() else None, random_seed=42)\n",
        "results = pipeline.run_full_pipeline(\n",
        "    n_sources=15000,\n",
        "    opt_n_sources=100,\n",
        "    opt_n_tasks=10,\n",
        "    train_ml=True,\n",
        "    solver_name=\"glpk\",\n",
        ")\n",
        "print(\"Results keys:\", list(results.keys()))\n",
        "if \"tssp\" in results:\n",
        "    print(\"TSSP solved:\", results[\"tssp\"].get(\"solved\"))\n",
        "if \"analysis\" in results:\n",
        "    print(\"Analysis keys:\", list(results[\"analysis\"].keys()))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
